## ğŸ“Š Random Forest Regression ëª¨ë¸ í™œìš©


  - ë‹¤ì–‘í•œ ë³€ìˆ˜ì™€ ë³µì¡í•œ ê´€ê³„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë‹¤ë£° ìˆ˜ ìˆìŒ
  - ë¹„ì„ í˜•ì ì¸ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ë° ìœ ë¦¬
  - ì…ë ¥ë³€ìˆ˜ê°€ ë‚˜ì´, ì„±ë³„, ëª©ì , ì§€ì—­ì˜ ë¹„ì„ í˜•ì ì¸ ê´€ê³„ì´ë¯€ë¡œ ëœë¤í¬ë ˆìŠ¤íŠ¸ê°€ ì í•©í•¨


### í”„ë¡œì íŠ¸ ê°œìš”
ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³ , ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ê°„ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ë°ì´í„° ë¡œë“œ, ì „ì²˜ë¦¬, í•™ìŠµ, í‰ê°€, ì‹œê°í™”ê¹Œì§€ì˜ ì „ì²´ ê³¼ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤.

---

#### ğŸ“‚ 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
```
- `numpy`: ìˆ˜ì¹˜ ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
- `pandas`: ë°ì´í„° í”„ë ˆì„ ì²˜ë¦¬
- `scikit-learn`: ëª¨ë¸ í•™ìŠµ, í‰ê°€ ë° ë°ì´í„° ë¶„ë¦¬
- `matplotlib`: ë°ì´í„° ì‹œê°í™”

#### ğŸ“‚ 2. ë°ì´í„° ë¡œë“œ ë° í™•ì¸

```python
file_path = 'D:\\study\\class\\ë¹…ë°\\random_forest_label_8_ëŒ€í”¼.csv'
rf_data = pd.read_csv(file_path)

print("Data Head:\n", rf_data.head())
print("Data Description:\n", rf_data.describe())
```
- ë°ì´í„°ë¥¼ ì§€ì •ëœ ê²½ë¡œì—ì„œ ë¡œë“œ
- `head()`: ë°ì´í„°ì˜ ìƒìœ„ 5ê°œ í–‰ì„ ì¶œë ¥
- `scikit-learn`: ëª¨ë¸ í•™ìŠµ, í‰ê°€ ë° ë°ì´í„° ë¶„ë¦¬
- `describe()`: ë°ì´í„°ì˜ í†µê³„ ìš”ì•½ ì •ë³´ë¥¼ ì œê³µ

#### ğŸ“‚ 3. ì…ë ¥ ë³€ìˆ˜ì™€ ì¶œë ¥ ë³€ìˆ˜ ë¶„ë¦¬
```python
X = rf_data[['gender', 'age', 'purpose', 'dest_hdong_cd']]
y = rf_data['score']

```
- `X`: ì…ë ¥ ë³€ìˆ˜
  - `gender`: ì„±ë³„
  - `age`: ë‚˜ì´
  - `purpose`: ëª©ì 
  - `dest_hdong_cd`: ëª©ì ì§€ ì½”ë“œ

- `y`: ì¶œë ¥ ë³€ìˆ˜
  - `score`: ì˜ˆì¸¡í•˜ë ¤ëŠ” ê°’
  
#### ğŸ“‚ 4. ë°ì´í„° ë¶„ë¦¬
```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```
- ë°ì´í„°ë¥¼ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë‚˜ëˆ”ëˆ”
- `test_size=0.2`: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨ì€ 20%ë¡œ ì„¤ì •
- `random_state=42`: ê²°ê³¼ ì¬í˜„ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ê³ ì •ê°’

#### ğŸ“‚ 5. ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ
```python
model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42)
```
- `n_estimators`: ëœë¤ í¬ë ˆìŠ¤íŠ¸ íŠ¸ë¦¬ì˜ ê°œìˆ˜ (100ê°œ)
- `max_depth`:ê° íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ (20ë‹¨ê³„)
- `random_state`: ê²°ê³¼ ì¬í˜„ì„±ì„ ë³´ì¥

#### ğŸ“‚ 6. ëª¨ë¸ ì˜ˆì¸¡
```python
y_pred = model.predict(X_test)
```
- í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°’ì„ ì˜ˆì¸¡

#### ğŸ“‚ 7. ì„±ëŠ¥ í‰ê°€
```python
mse = mean_squared_error(y_test, y_pred)max_depth=20, random_state=42)
r2 = r2_score(y_test, y_pred)
```
- í‰ê°€ ê²°ê³¼
- `MSE (Mean Squared Error)`: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ê°„ì˜ ì˜¤ì°¨ë¥¼ í‰ê°€
- `RÂ² (R-squared Score)`: ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¸¡ì • (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)

#### ğŸ“‚ 8. Feature Importance í™•ì¸
```python
importances = model.feature_importances_
```
- ê° ì…ë ¥ ë³€ìˆ˜`(X)`ê°€ ëª¨ë¸ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¶œë ¥

### ëª¨ë¸ ê°€ì¤‘ì¹˜

| Model | Acc     | Weight               |
| :-------- | :------- | :------------------------- |
| **ì˜ì‚¬ ê²°ì • íŠ¸ë¦¬**| `string` | **Required**. Your API key |